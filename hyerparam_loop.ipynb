{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb5bbfa-05c5-4bac-be2b-53ead5bf3e6f",
   "metadata": {},
   "source": [
    "## RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771c52a6-f6ab-4ae0-806d-a097aa690efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_filters1 = trial.suggest_categorical(\"num_filters1\", [32, 64, 128])\n",
    "    num_filters2 = trial.suggest_categorical(\"num_filters2\", [64, 128, 256])\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5])\n",
    "    pooling_type = trial.suggest_categorical(\"pooling\", [\"max\", \"avg\"])\n",
    "    fc_size = trial.suggest_categorical(\"fc_size\", [128, 256, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    \n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, num_filters1, kernel_size, padding=1)\n",
    "            self.conv2 = nn.Conv2d(num_filters1, num_filters2, kernel_size, padding=1)\n",
    "            self.pool = nn.MaxPool2d(2, 2) if pooling_type == \"max\" else nn.AvgPool2d(2, 2)\n",
    "            #self.fc1 = nn.Linear(num_filters2 * 8 * 8, fc_size)\n",
    "            self._to_linear = None  # Placeholder for dynamically determined size\n",
    "            self.fc2 = nn.Linear(fc_size, 10)\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            if self._to_linear is None:  # Calculate dynamically\n",
    "                self._to_linear = x.view(x.size(0), -1).shape[1]\n",
    "                self.fc1 = nn.Linear(self._to_linear, fc_size).to(device)  # Initialize after knowing size\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "        # def forward(self, x):\n",
    "        #     x = self.pool(F.relu(self.conv1(x)))\n",
    "        #     x = self.pool(F.relu(self.conv2(x)))\n",
    "        #     x = x.view(x.size(0), -1)\n",
    "        #     #print(\"Flattened size:\", x.shape)\n",
    "        #     x = F.relu(self.fc1(x))\n",
    "        #     x = self.dropout(x)\n",
    "        #     x = self.fc2(x)\n",
    "        #     return x\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 3  # Small value for quick tuning\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Optuna will maximize this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1134414-8f1e-4aa0-977e-3857e6218e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 00:37:05,670] A new study created in memory with name: no-name-44c3efc1-81c1-4a0d-920c-a7808b132a54\n",
      "[I 2025-03-18 00:37:44,284] Trial 0 finished with value: 0.4422 and parameters: {'num_filters1': 32, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 512, 'dropout_rate': 0.2544680684127717, 'learning_rate': 0.00022599420266733583}. Best is trial 0 with value: 0.4422.\n",
      "[I 2025-03-18 00:38:22,036] Trial 1 finished with value: 0.4619 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 512, 'dropout_rate': 0.22605048829444196, 'learning_rate': 0.0003669976304852994}. Best is trial 1 with value: 0.4619.\n",
      "[I 2025-03-18 00:39:00,236] Trial 2 finished with value: 0.5661 and parameters: {'num_filters1': 128, 'num_filters2': 64, 'kernel_size': 5, 'pooling': 'avg', 'fc_size': 512, 'dropout_rate': 0.46175040925588634, 'learning_rate': 0.0010871993567913908}. Best is trial 2 with value: 0.5661.\n",
      "[I 2025-03-18 00:39:38,254] Trial 3 finished with value: 0.4897 and parameters: {'num_filters1': 64, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 128, 'dropout_rate': 0.3462245073798855, 'learning_rate': 0.0005510040664349384}. Best is trial 2 with value: 0.5661.\n",
      "[I 2025-03-18 00:40:16,253] Trial 4 finished with value: 0.6085 and parameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 256, 'dropout_rate': 0.4535517889809642, 'learning_rate': 0.0027866759720100087}. Best is trial 4 with value: 0.6085.\n",
      "[I 2025-03-18 00:40:54,276] Trial 5 finished with value: 0.4678 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 5, 'pooling': 'max', 'fc_size': 256, 'dropout_rate': 0.49556003029492934, 'learning_rate': 0.00021854132979181443}. Best is trial 4 with value: 0.6085.\n",
      "[I 2025-03-18 00:41:32,461] Trial 6 finished with value: 0.5425 and parameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 256, 'dropout_rate': 0.35935873766063653, 'learning_rate': 0.001879247470521349}. Best is trial 4 with value: 0.6085.\n",
      "[I 2025-03-18 00:42:10,318] Trial 7 finished with value: 0.5059 and parameters: {'num_filters1': 64, 'num_filters2': 64, 'kernel_size': 5, 'pooling': 'avg', 'fc_size': 256, 'dropout_rate': 0.24355841423673488, 'learning_rate': 0.00034671641855823853}. Best is trial 4 with value: 0.6085.\n",
      "[I 2025-03-18 00:42:48,060] Trial 8 finished with value: 0.5609 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 5, 'pooling': 'max', 'fc_size': 512, 'dropout_rate': 0.38548454645266683, 'learning_rate': 0.0007936171767346275}. Best is trial 4 with value: 0.6085.\n",
      "[I 2025-03-18 00:43:26,428] Trial 9 finished with value: 0.6013 and parameters: {'num_filters1': 128, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 512, 'dropout_rate': 0.48407756704622346, 'learning_rate': 0.009875430786323898}. Best is trial 4 with value: 0.6085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 256, 'dropout_rate': 0.4535517889809642, 'learning_rate': 0.0027866759720100087}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # We want to maximize accuracy\n",
    "study.optimize(objective, n_trials=10)  # Try 10 different sets of hyperparameters\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb71b56-40c0-4e39-8cc3-f45694ea0cbe",
   "metadata": {},
   "source": [
    "## Leaky Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "056ac2bc-d8e6-4e48-b293-ffd2f7f91e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 01:37:29,811] A new study created in memory with name: no-name-17ad5d5b-9314-4233-a066-cdd18344da28\n",
      "[I 2025-03-19 01:38:47,995] Trial 0 finished with value: 0.6667 and parameters: {'num_filters1': 128, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 128, 'dropout_rate': 0.49510579884377515, 'learning_rate': 0.0002962684136310157, 'negative_slope': 0.2002021884267643}. Best is trial 0 with value: 0.6667.\n",
      "[I 2025-03-19 01:40:05,814] Trial 1 finished with value: 0.7308 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 128, 'dropout_rate': 0.2511333667432508, 'learning_rate': 0.0013823321576015332, 'negative_slope': 0.012050539375327133}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:41:22,965] Trial 2 finished with value: 0.6946 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 5, 'pooling': 'avg', 'fc_size': 128, 'dropout_rate': 0.23314932298749744, 'learning_rate': 0.0031266369418477035, 'negative_slope': 0.13735629655025716}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:42:40,046] Trial 3 finished with value: 0.6952 and parameters: {'num_filters1': 128, 'num_filters2': 64, 'kernel_size': 5, 'pooling': 'avg', 'fc_size': 512, 'dropout_rate': 0.4504654969300385, 'learning_rate': 0.0004508893105026468, 'negative_slope': 0.12610496157745107}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:43:57,051] Trial 4 finished with value: 0.7194 and parameters: {'num_filters1': 32, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 256, 'dropout_rate': 0.3468315733024414, 'learning_rate': 0.004610582141972216, 'negative_slope': 0.07269346224580761}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:45:13,852] Trial 5 finished with value: 0.7128 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 512, 'dropout_rate': 0.2181992312880454, 'learning_rate': 0.0007522450988946906, 'negative_slope': 0.29755806370518334}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:46:30,816] Trial 6 finished with value: 0.7308 and parameters: {'num_filters1': 128, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 128, 'dropout_rate': 0.4186905424798796, 'learning_rate': 0.0018839979910819354, 'negative_slope': 0.12446309726904602}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:47:47,510] Trial 7 finished with value: 0.6448 and parameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 5, 'pooling': 'avg', 'fc_size': 128, 'dropout_rate': 0.36242108998053757, 'learning_rate': 0.0037846979511414725, 'negative_slope': 0.24217039864216103}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:49:04,132] Trial 8 finished with value: 0.6306 and parameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 256, 'dropout_rate': 0.4765583546517158, 'learning_rate': 0.0051213069992539105, 'negative_slope': 0.2577493144855189}. Best is trial 1 with value: 0.7308.\n",
      "[I 2025-03-19 01:50:20,847] Trial 9 finished with value: 0.6449 and parameters: {'num_filters1': 64, 'num_filters2': 128, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 128, 'dropout_rate': 0.42965033241641865, 'learning_rate': 0.006294639922845225, 'negative_slope': 0.2419310960846862}. Best is trial 1 with value: 0.7308.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 128, 'dropout_rate': 0.2511333667432508, 'learning_rate': 0.0013823321576015332, 'negative_slope': 0.012050539375327133}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_filters1 = trial.suggest_categorical(\"num_filters1\", [32, 64, 128])\n",
    "    num_filters2 = trial.suggest_categorical(\"num_filters2\", [64, 128, 256])\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5])\n",
    "    pooling_type = trial.suggest_categorical(\"pooling\", [\"max\", \"avg\"])\n",
    "    fc_size = trial.suggest_categorical(\"fc_size\", [128, 256, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    negative_slope = trial.suggest_float(\"negative_slope\", 0.01, 0.3)  # Tuning LeakyReLU slope\n",
    "    \n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, num_filters1, kernel_size, padding=1)\n",
    "            self.conv2 = nn.Conv2d(num_filters1, num_filters2, kernel_size, padding=1)\n",
    "            self.pool = nn.MaxPool2d(2, 2) if pooling_type == \"max\" else nn.AvgPool2d(2, 2)\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "            # Dummy forward pass to determine `self._to_linear`\n",
    "            dummy_input = torch.randn(1, 3, 32, 32)  # CIFAR-10 image size\n",
    "            with torch.no_grad():\n",
    "                dummy_out = self._feature_extractor(dummy_input)\n",
    "                self._to_linear = dummy_out.view(1, -1).shape[1]\n",
    "\n",
    "            self.fc1 = nn.Linear(self._to_linear, fc_size)\n",
    "            self.fc2 = nn.Linear(fc_size, 10)\n",
    "\n",
    "        def _feature_extractor(self, x):\n",
    "            x = self.pool(F.leaky_relu(self.conv1(x), negative_slope))\n",
    "            x = self.pool(F.leaky_relu(self.conv2(x), negative_slope))\n",
    "            return x\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self._feature_extractor(x)\n",
    "            x = x.view(x.size(0), -1)  # Flatten\n",
    "            x = self.dropout(F.leaky_relu(self.fc1(x), negative_slope))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 5  # Small value for quick tuning\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Optuna will maximize this\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=10)  \n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2aca1-a910-46e5-b5f2-017ba064d7b2",
   "metadata": {},
   "source": [
    "## Elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03631233-a234-4de9-b278-5fa4b3d6beb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 01:58:38,158] A new study created in memory with name: no-name-3c399ec2-f354-4bc4-9396-50e0b050026a\n",
      "[I 2025-03-19 01:59:54,451] Trial 0 finished with value: 0.5076 and parameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 5, 'pooling': 'max', 'fc_size': 128, 'dropout_rate': 0.4165034118011366, 'learning_rate': 0.004246662145521995, 'alpha': 0.9896529216312571}. Best is trial 0 with value: 0.5076.\n",
      "[I 2025-03-19 02:01:10,229] Trial 1 finished with value: 0.5406 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 256, 'dropout_rate': 0.2420231527040384, 'learning_rate': 0.00010767904128956026, 'alpha': 0.5239840053117389}. Best is trial 1 with value: 0.5406.\n",
      "[I 2025-03-19 02:02:26,318] Trial 2 finished with value: 0.1 and parameters: {'num_filters1': 32, 'num_filters2': 128, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 128, 'dropout_rate': 0.21092927395696745, 'learning_rate': 0.009839815507054503, 'alpha': 0.5879721807899672}. Best is trial 1 with value: 0.5406.\n",
      "[I 2025-03-19 02:03:42,395] Trial 3 finished with value: 0.6314 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 256, 'dropout_rate': 0.2979921205210342, 'learning_rate': 0.008613845002677483, 'alpha': 0.40846073301490515}. Best is trial 3 with value: 0.6314.\n",
      "[I 2025-03-19 02:04:58,371] Trial 4 finished with value: 0.6877 and parameters: {'num_filters1': 32, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 512, 'dropout_rate': 0.4965536639024271, 'learning_rate': 0.0027312742675493847, 'alpha': 0.49159804670566515}. Best is trial 4 with value: 0.6877.\n",
      "[I 2025-03-19 02:06:14,621] Trial 5 finished with value: 0.7246 and parameters: {'num_filters1': 128, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 512, 'dropout_rate': 0.2525871431125819, 'learning_rate': 0.0025973752491179067, 'alpha': 0.07234758616795293}. Best is trial 5 with value: 0.7246.\n",
      "[I 2025-03-19 02:07:31,028] Trial 6 finished with value: 0.6755 and parameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 512, 'dropout_rate': 0.35726050196694314, 'learning_rate': 0.0016990716616538729, 'alpha': 0.610087743080011}. Best is trial 5 with value: 0.7246.\n",
      "[I 2025-03-19 02:08:47,073] Trial 7 finished with value: 0.1 and parameters: {'num_filters1': 32, 'num_filters2': 256, 'kernel_size': 5, 'pooling': 'avg', 'fc_size': 512, 'dropout_rate': 0.27784331080340763, 'learning_rate': 0.007784481494563665, 'alpha': 0.25457827865256205}. Best is trial 5 with value: 0.7246.\n",
      "[I 2025-03-19 02:10:03,479] Trial 8 finished with value: 0.7087 and parameters: {'num_filters1': 64, 'num_filters2': 256, 'kernel_size': 5, 'pooling': 'max', 'fc_size': 128, 'dropout_rate': 0.46898753048561426, 'learning_rate': 0.0003493867219022223, 'alpha': 0.8997237344862914}. Best is trial 5 with value: 0.7246.\n",
      "[I 2025-03-19 02:11:19,432] Trial 9 finished with value: 0.6952 and parameters: {'num_filters1': 64, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'avg', 'fc_size': 128, 'dropout_rate': 0.23079115124256652, 'learning_rate': 0.0024917613550454734, 'alpha': 0.48585974495434636}. Best is trial 5 with value: 0.7246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_filters1': 128, 'num_filters2': 64, 'kernel_size': 3, 'pooling': 'max', 'fc_size': 512, 'dropout_rate': 0.2525871431125819, 'learning_rate': 0.0025973752491179067, 'alpha': 0.07234758616795293}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_filters1 = trial.suggest_categorical(\"num_filters1\", [32, 64, 128])\n",
    "    num_filters2 = trial.suggest_categorical(\"num_filters2\", [64, 128, 256])\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5])\n",
    "    pooling_type = trial.suggest_categorical(\"pooling\", [\"max\", \"avg\"])\n",
    "    fc_size = trial.suggest_categorical(\"fc_size\", [128, 256, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.01, 1.0)  # Alpha parameter for ELU\n",
    "    \n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, num_filters1, kernel_size, padding=1)\n",
    "            self.conv2 = nn.Conv2d(num_filters1, num_filters2, kernel_size, padding=1)\n",
    "            self.pool = nn.MaxPool2d(2, 2) if pooling_type == \"max\" else nn.AvgPool2d(2, 2)\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "            # Dummy forward pass to determine `self._to_linear`\n",
    "            dummy_input = torch.randn(1, 3, 32, 32)  # CIFAR-10 image size\n",
    "            with torch.no_grad():\n",
    "                dummy_out = self._feature_extractor(dummy_input)\n",
    "                self._to_linear = dummy_out.view(1, -1).shape[1]\n",
    "\n",
    "            self.fc1 = nn.Linear(self._to_linear, fc_size)\n",
    "            self.fc2 = nn.Linear(fc_size, 10)\n",
    "\n",
    "        def _feature_extractor(self, x):\n",
    "            x = self.pool(F.elu(self.conv1(x), alpha))\n",
    "            x = self.pool(F.elu(self.conv2(x), alpha))\n",
    "            return x\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self._feature_extractor(x)\n",
    "            x = x.view(x.size(0), -1)  # Flatten\n",
    "            x = self.dropout(F.elu(self.fc1(x), alpha))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 5  # Small value for quick tuning\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Optuna will maximize this\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=10)  \n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d9f83-a1d6-4c30-977e-958732dacf77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
